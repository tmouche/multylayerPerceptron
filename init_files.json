{
    "general": {
        "learningRate": 0.005,
        "batchSize": 30,
        "epochs": 84,
        "loss": "crossEntropy"
    },
    "layer": {    
        "0": {
            "unit": "input",
            "size": 30
        },
        "1": {
            "unit": "hidden",
            "size": 10,
            "activation": "sigmoid",
            "initializer": "heNormal"
        },
        "2": {
            "unit": "output",
            "size": 2,
            "activation": "softmax",
            "initializer": "xaviereNormal"
        }
    }
}